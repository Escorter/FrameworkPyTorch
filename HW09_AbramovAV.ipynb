{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c8e2a9",
   "metadata": {},
   "source": [
    "### Домашняя работа к уроку 9\n",
    "### Студент: Абрамов А.В."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a3479",
   "metadata": {},
   "source": [
    "Возьмите готовую модель из https://huggingface.co/models для классификации сентимента текста.\n",
    "Сделайте предсказания на всем df_val. \n",
    "Посчитайте метрику качества.\n",
    "Дообучите эту модель на df_train. Посчитайте метрику качества на df_val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03997eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:02.536031Z",
     "start_time": "2023-12-02T16:39:59.766774Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from transformers import pipeline\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from transformers import BertModel\n",
    "\n",
    "#from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9c8bcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:04.288494Z",
     "start_time": "2023-12-02T16:40:03.831157Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_val = pd.read_csv('val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0e2e2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:06.210865Z",
     "start_time": "2023-12-02T16:40:06.198897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((181467, 3), (22683, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cfa2bd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:08.994020Z",
     "start_time": "2023-12-02T16:40:08.983049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77cfe576",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:12.599088Z",
     "start_time": "2023-12-02T16:40:12.583132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    92063\n",
       "0    89404\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['class'].value_counts() #достаточно сбалансированный датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fb8914",
   "metadata": {},
   "source": [
    "#### Возьмите готовую модель из https://huggingface.co/models для классификации сентимента текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c37bdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:16.099087Z",
     "start_time": "2023-12-02T16:40:13.647184Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment = pipeline(\"text-classification\", model='blanchefort/rubert-base-cased-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2bda24b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:18.086402Z",
     "start_time": "2023-12-02T16:40:17.895083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8849804997444153}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('Сервис на высоте!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a09a634",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:19.047999Z",
     "start_time": "2023-12-02T16:40:19.007133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEUTRAL', 'score': 0.7820937037467957}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('Можно заказать устрицы')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "289e04e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:19.704223Z",
     "start_time": "2023-12-02T16:40:19.663332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.7507331967353821}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('Долго несут заказ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40232fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:20.297892Z",
     "start_time": "2023-12-02T16:40:20.255009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я просто неудачик, поцарапал экран на телефоне ((\n",
      "Dataset label is negative\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9949102997779846}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 8\n",
    "print(df_train.iloc[idx]['text'])\n",
    "print('Dataset label is', ('positive'if df_train.iloc[idx]['class']==1 else 'negative'))\n",
    "sentiment(df_train.iloc[idx]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2792ca53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:25.093744Z",
     "start_time": "2023-12-02T16:40:24.935160Z"
    }
   },
   "outputs": [],
   "source": [
    "# переведем текст сообщений в нижний регистр\n",
    "df_train['text'] = df_train['text'].apply(lambda x: x.lower())\n",
    "df_val['text'] = df_val['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bedc848",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:26.210489Z",
     "start_time": "2023-12-02T16:40:25.871207Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6f706b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:27.408495Z",
     "start_time": "2023-12-02T16:40:27.046951Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "570872a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:28.994043Z",
     "start_time": "2023-12-02T16:40:28.983087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 14337, 33930, 77572, 10520, 84964, 15065, 33917,   102,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "example_text = 'Пример текста для токенизации'\n",
    "bert_input = tokenizer(example_text, padding='max_length', max_length=10, \n",
    "                       truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3d9b5c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:32.263424Z",
     "start_time": "2023-12-02T16:40:32.255445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('F', 'текста')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.ids_to_tokens[143], tokenizer.ids_to_tokens[77572]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee14f2a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:33.511952Z",
     "start_time": "2023-12-02T16:40:33.502976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Пример текста для токенизации [SEP] [PAD]\n"
     ]
    }
   ],
   "source": [
    "example_text = tokenizer.decode(bert_input.input_ids[0])\n",
    "\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "383a703f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:36.566123Z",
     "start_time": "2023-12-02T16:40:36.551164Z"
    }
   },
   "outputs": [],
   "source": [
    "class TwitterDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, txts, labels):\n",
    "        self._labels = labels\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        self._txts = [self.tokenizer(text, padding='max_length', max_length=10,\n",
    "                                     truncation=True, return_tensors=\"pt\")\n",
    "                      for text in txts]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._txts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self._txts[index], self._labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d69fa9a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:41:54.068223Z",
     "start_time": "2023-12-02T16:40:38.359088Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = df_train['class'].values\n",
    "y_val = df_val['class'].values\n",
    "\n",
    "train_dataset = TwitterDataset(df_train['text'], y_train)\n",
    "valid_dataset = TwitterDataset(df_val['text'], y_val)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                          batch_size=64,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                          batch_size=64,\n",
    "                          shuffle=False,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592969a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-02T15:33:58.017Z"
    }
   },
   "outputs": [],
   "source": [
    "#for txt, lbl in train_loader:\n",
    "#    print(txt.keys())\n",
    "#    print(txt['input_ids'].shape)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32dc30e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:44:04.771306Z",
     "start_time": "2023-12-02T16:44:04.759339Z"
    }
   },
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \n",
    "        _, pooled_output = self.bert(input_ids=x, attention_mask=mask, return_dict=False)\n",
    "        # _, pooled_output - набор эмбеддинигов слов, эмбеддинг предложения\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.sigm(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38760b7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:44:08.280395Z",
     "start_time": "2023-12-02T16:44:08.271419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "729ebd73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:44:12.737213Z",
     "start_time": "2023-12-02T16:44:11.319271Z"
    }
   },
   "outputs": [],
   "source": [
    "model = BertClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = Adam(model.linear.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01415e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T16:32:51.917676Z",
     "start_time": "2023-12-02T16:32:51.902527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertClassifier(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (sigm): Sigmoid()\n",
      ")\n",
      "Parameters full train: 177854978\n",
      "Parameters transfer learning: 1538\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(\"Parameters full train:\", sum([param.nelement() for param in model.parameters()]))\n",
    "print(\"Parameters transfer learning:\", sum([param.nelement() for param in model.linear.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d813aecb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-02T16:44:16.814Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/2836 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(2):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "\n",
    "    model.train()\n",
    "    for train_input, train_label in tqdm(train_loader):\n",
    "        mask = train_input['attention_mask'].to(device)\n",
    "        input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "        train_label = train_label.to(device)\n",
    "\n",
    "        output = model(input_id, mask)\n",
    "                \n",
    "        batch_loss = criterion(output, train_label)\n",
    "        total_loss_train += batch_loss.item()\n",
    "                \n",
    "        acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "        total_acc_train += acc\n",
    "\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    model.eval()\n",
    "    total_loss_val, total_acc_val = 0.0, 0.0\n",
    "    for val_input, val_label in valid_loader:\n",
    "        val_label = val_label.to(device)\n",
    "        mask = val_input['attention_mask'].to(device)\n",
    "        input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "        output = model(input_id, mask)\n",
    "\n",
    "        batch_loss = criterion(output, val_label)\n",
    "        total_loss_val += batch_loss.item()\n",
    "                    \n",
    "        acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "        total_acc_val += acc\n",
    "            \n",
    "    print(\n",
    "        f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_dataset): .3f} \\\n",
    "        | Train Accuracy: {total_acc_train / len(train_dataset): .3f} \\\n",
    "        | Val Loss: {total_loss_val / len(valid_dataset): .3f} \\\n",
    "        | Val Accuracy: {total_acc_val / len(valid_dataset): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57267ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
