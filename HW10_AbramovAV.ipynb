{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a301989c",
   "metadata": {},
   "source": [
    "### Домашняя работа к уроку 10\n",
    "### Студент: Абрамов А.В."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decca35b",
   "metadata": {},
   "source": [
    "Задание по итогам курса:\n",
    "(упрощенное/для тех, у кого нет вебкамеры)\n",
    "\n",
    "Нужно написать приложение, которое будет получать на вход изображение.\n",
    "В процессе определять, что перед камерой находится человек, задетектировав его лицо на кадре.\n",
    "На изображении человек показывает жесты руками, а алгоритм должен считать их и классифицировать.\n",
    "(более сложное)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9e459c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T21:01:23.180579Z",
     "start_time": "2023-12-10T21:01:21.503618Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e60c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "model_state = torch.load('emotion_detection_model_state.pth', map_location=torch.device('cpu'))\n",
    "class_labels = [\"Angry\", \"Happy\", \"Neutral\", \"Sad\", \"Suprise\"]\n",
    "\n",
    "\n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ELU(inplace=True),\n",
    "    ]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "    ]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = conv_block(in_channels, 64)\n",
    "\n",
    "        self.conv1 = conv_block(64, 64, pool=True)\n",
    "        self.res1 = nn.Sequential(conv_block(64, 32), conv_block(32, 64))\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.conv2 = conv_block(64, 64, pool=True)\n",
    "        self.res2 = nn.Sequential(conv_block(64, 32), conv_block(32, 64))\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.conv3 = conv_block(64, 64, pool=True)\n",
    "        self.res3 = nn.Sequential(conv_block(64, 32), conv_block(32, 64))\n",
    "        self.drop3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.MaxPool2d(6), nn.Flatten(), nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, xb):\n",
    "        out = self.input(xb)\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.drop1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.drop2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.res3(out) + out\n",
    "        out = self.drop3(out)\n",
    "\n",
    "        return self.classifier(out)\n",
    "\n",
    "\n",
    "model = ResNet(1, len(class_labels))\n",
    "model.load_state_dict(model_state)\n",
    "\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.imread('Test001.jpg')\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    #ret, frame = cap.read()\n",
    "    frame = cap\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    labels = []\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y : y + h, x : x + w]\n",
    "        roi_gray = cv2.resize(roi_gray, (48, 48), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        if np.sum([roi_gray]) != 0:\n",
    "            roi = tt.functional.to_pil_image(roi_gray)\n",
    "            roi = tt.functional.to_grayscale(roi)\n",
    "            roi = tt.ToTensor()(roi).unsqueeze(0)\n",
    "\n",
    "            # make a prediction on the ROI\n",
    "            tensor = model(roi)\n",
    "            pred = torch.max(tensor, dim=1)[1].tolist()\n",
    "            label = class_labels[pred[0]]\n",
    "\n",
    "            label_position = (x, y)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                label,\n",
    "                label_position,\n",
    "                cv2.FONT_HERSHEY_COMPLEX,\n",
    "                2,\n",
    "                (0, 255, 0),\n",
    "                3,\n",
    "            )\n",
    "        else:\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                \"No Face Found\",\n",
    "                (20, 60),\n",
    "                cv2.FONT_HERSHEY_COMPLEX,\n",
    "                2,\n",
    "                (0, 255, 0),\n",
    "                3,\n",
    "            )\n",
    "\n",
    "    cv2.imshow(\"Emotion Detector\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "#cap.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef6cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
